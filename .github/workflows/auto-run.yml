name: Auto Run (Daily)

on:
  schedule:
    # Weekdays at 22:00 UTC / 5:00 PM ET (after US market close)
    # Starts first â€” slowest engine (up to 3 hrs), must finish before 9:30 PM ET collection
    - cron: "0 22 * * 1-5"
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"
  PYTHONUNBUFFERED: "1"

concurrency:
  group: auto-run
  cancel-in-progress: true

jobs:
  run:
    name: Run main.py all
    runs-on: ubuntu-latest
    timeout-minutes: 180
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Rebuild price database
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          rm -f data/prices.db
          START_DATE=$(date -u -d "400 days ago" +%Y-%m-%d)
          END_DATE=$(date -u +%Y-%m-%d)
          echo "Rebuilding prices.db from ${START_DATE} to ${END_DATE}"
          python main.py db download --start "${START_DATE}" --end "${END_DATE}" --config config/default.yaml --workers 8

      - name: Run full scan
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
          ADANOS_API_KEY: ${{ secrets.ADANOS_API_KEY }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}
        run: |
          python main.py all --config config/default.yaml

      - name: Push results to Heroku API
        if: success()
        env:
          KOOCORE_HEROKU_URL: ${{ secrets.KOOCORE_HEROKU_URL }}
          ENGINE_API_KEY: ${{ secrets.ENGINE_API_KEY }}
        run: |
          if [ -z "${KOOCORE_HEROKU_URL}" ]; then
            echo "ERROR: KOOCORE_HEROKU_URL is not configured"
            exit 1
          fi

          HYBRID_FILE=$(ls -t outputs/*/hybrid_analysis_*.json 2>/dev/null | head -1)
          if [ -z "${HYBRID_FILE}" ]; then
            echo "ERROR: No hybrid_analysis_*.json file found under outputs/"
            exit 1
          fi

          RUN_DATE=$(basename "${HYBRID_FILE}" | sed -E 's/^hybrid_analysis_([0-9]{4}-[0-9]{2}-[0-9]{2})\.json$/\1/')
          if [ -z "${RUN_DATE}" ]; then
            echo "ERROR: Could not derive run_date from ${HYBRID_FILE}"
            exit 1
          fi

          echo "Pushing ${HYBRID_FILE} to ${KOOCORE_HEROKU_URL} for run_date=${RUN_DATE}"
          export HYBRID_FILE RUN_DATE
          PAYLOAD=$(python - <<'PY'
          import json
          import os

          with open(os.environ["HYBRID_FILE"], "r", encoding="utf-8") as f:
              hybrid = json.load(f)

          print(
              json.dumps(
                  {
                      "hybrid_analysis": hybrid,
                      "run_date": os.environ["RUN_DATE"],
                      "pipeline_duration_s": None,
                  }
              )
          )
          PY
          )

          HTTP_CODE=$(curl -sS -o /tmp/ingest_response.json -w "%{http_code}" -X POST "${KOOCORE_HEROKU_URL}/api/engine/ingest" \
            -H "Content-Type: application/json" \
            -H "X-Engine-Key: ${ENGINE_API_KEY}" \
            -d "${PAYLOAD}" \
            --max-time 30)

          echo "Ingest response HTTP ${HTTP_CODE}: $(cat /tmp/ingest_response.json)"
          if [ "${HTTP_CODE}" -lt 200 ] || [ "${HTTP_CODE}" -ge 300 ]; then
            echo "ERROR: Ingest failed"
            exit 1
          fi

      - name: Commit outputs to repo
        if: success()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add outputs/
          if git diff --cached --quiet; then
            echo "No new outputs to commit"
          else
            DATE=$(date -u +%Y-%m-%d)
            git commit -m "auto: outputs for ${DATE}"
            # Keep workflow green even if origin moved (another run pushed first).
            if ! git push origin HEAD:main; then
              echo "WARN: output push failed due to race/non-fast-forward (non-fatal)"
            fi
          fi

      - name: Upload outputs artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: outputs
          path: outputs/**
          retention-days: 7
